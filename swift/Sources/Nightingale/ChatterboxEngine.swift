import Foundation
import MLX
import MLXNN
import MLXRandom
import AVFoundation

/// ChatterboxEngine - The Dual Soul TTS Engine for iOS
/// Manages model loading, voice injection, and audio streaming
public actor ChatterboxEngine {

    // MARK: - Models

    private var t3: T3Model?
    public private(set) var s3gen: S3Gen?
    private var vocab: [String: Int]?
    private var bpeMerges: [(String, String)]?  // BPE merge rules

    /// Get S3Gen for direct testing
    public func getS3Gen() -> S3Gen? {
        return s3gen
    }

    /// Get T3 for direct testing
    public func getT3() -> T3Model? {
        return t3
    }

    /// Get speech embedding matrix from T3
    public func getSpeechEmbMatrix() -> MLXArray? {
        return t3?.speechEmb.weight
    }

    /// Get voice conditioning data for direct S3Gen testing
    public func getVoiceConditioning() -> (s3Soul: MLXArray, promptToken: MLXArray, promptFeat: MLXArray)? {
        guard let s3 = s3Soul, let pt = promptToken, let pf = promptFeat else {
            return nil
        }
        return (s3, pt, pf)
    }

    /// Tokenize text for testing
    public func tokenizeText(_ text: String) throws -> MLXArray {
        let tokens = tokenize(text)
        return MLXArray(tokens.map { Int32($0) }).reshaped([1, tokens.count])
    }

    // MARK: - Voice State (Dual Souls)

    private var t3Soul: MLXArray?           // 256-dim speaker embedding for T3
    private var s3Soul: MLXArray?           // 192-dim speaker embedding for S3Gen
    private var t3CondTokens: MLXArray?     // Conditioning tokens for T3
    private var promptToken: MLXArray?      // S3Gen prompt tokens
    private var promptFeat: MLXArray?       // S3Gen prompt features
    
    // Token Chaining State
    private var lastSpeechTokens: [Int] = []

    // Public accessors for testing
    public var t3Model: T3Model? { t3 }
    public var promptTokens: MLXArray? { promptToken }
    public var promptFeatures: MLXArray? { promptFeat }
    public var s3SpeakerEmb: MLXArray? { s3Soul }
    public var t3SpeakerEmb: MLXArray? { t3Soul }
    public var t3ConditioningTokens: MLXArray? { t3CondTokens }

    // MARK: - Audio Engine

    private let audioEngine = AVAudioEngine()
    private let audioPlayer = AVAudioPlayerNode()
    private let audioFormat: AVAudioFormat

    // MARK: - State

    public private(set) var isLoaded = false
    public private(set) var isVoiceLoaded = false

    // MARK: - Initialization

    public init() {
        self.audioFormat = AVAudioFormat(standardFormatWithSampleRate: 24000, channels: 1)!
        // Setup audio inline to avoid actor isolation issues
        audioEngine.attach(audioPlayer)
        audioEngine.connect(audioPlayer, to: audioEngine.mainMixerNode, format: audioFormat)

        // Note: Audio engine start/play causes crashes in some test environments
        // Commented out for command-line testing
        // do {
        //     try audioEngine.start()
        //     audioPlayer.play()
        // } catch {
        //     print("Failed to start audio engine: \(error)")
        // }
    }

    // MARK: - Model Loading

    /// Load the T3 and S3Gen models from the app bundle or specified URL
    public func loadModels(from bundle: Bundle = .main, modelsURL: URL? = nil) async throws {
        print("Loading Chatterbox models...")

        // CRITICAL: Set aggressive memory limits for iOS
        // iPhone 16 Pro has ~3.5GB safe limit (jetsam at ~4.5GB)
        let cacheLimitMB = 256  // Increased for quantized model inference
        GPU.set(cacheLimit: cacheLimitMB * 1024 * 1024)
        print("GPU cache limit set to \(cacheLimitMB)MB")

        // Find model directory
        let modelDir: URL
        if let url = modelsURL {
            modelDir = url
        } else if let url = bundle.url(forResource: "models", withExtension: nil)?.appendingPathComponent("chatterbox") {
            modelDir = url
        } else {
            print("ERROR: Could not find models/chatterbox in bundle")
            throw ChatterboxError.modelNotFound("models/chatterbox directory not found in bundle")
        }
        print("Using model directory: \(modelDir.path)")

        // Load config
        let configURL = modelDir.appendingPathComponent("config.json")
        let configData = try Data(contentsOf: configURL)
        let config = try JSONDecoder().decode(T3Config.self, from: configData)
        print("Config loaded: \(config.modelType)")

        // Load T3 weights - prefer FP32 if available, fallback to Q4
        let fp32URL = modelDir.appendingPathComponent("t3_fp32.safetensors")
        let q4URL = modelDir.appendingPathComponent("model.safetensors")
        let ropeFreqsURL = modelDir.appendingPathComponent("rope_freqs_llama3.safetensors")
        var rawWeights: [String: MLXArray]? = nil

        // Check for FP32 weights first (perfect precision, 2GB)
        if FileManager.default.fileExists(atPath: fp32URL.path) {
            print("Loading FP32 T3 weights from \(fp32URL.lastPathComponent)...")
            rawWeights = try MLX.loadArrays(url: fp32URL)
            print("Loaded \(rawWeights!.count) FP32 weight arrays")

            // Remap keys from Python naming to Swift naming for T3
            let t3Weights = remapT3Keys(rawWeights!)
            print("Remapped to \(t3Weights.count) T3 FP32 weights")

            // Create T3Model WITH FP32 weights
            print("Creating T3Model with FP32 weights for perfect precision...")
            self.t3 = T3Model(config: config, weights: t3Weights, ropeFreqsURL: ropeFreqsURL)
        }
        // Fallback to Q4 quantized weights (smaller, 470MB)
        else if FileManager.default.fileExists(atPath: q4URL.path) {
            print("Loading Q4 quantized weights from \(q4URL.lastPathComponent)...")
            rawWeights = try MLX.loadArrays(url: q4URL)
            print("Loaded \(rawWeights!.count) Q4 weight arrays from safetensors")

            // Remap keys from Python naming to Swift naming for T3
            let t3Weights = remapT3Keys(rawWeights!)
            print("Remapped to \(t3Weights.count) T3 weights")

            // Create T3Model WITH weights (supports quantized 4-bit layers)
            print("Creating T3Model with Q4 quantized weight loading...")
            self.t3 = T3Model(config: config, weights: t3Weights, ropeFreqsURL: ropeFreqsURL)
        } else {
            print("Warning: No T3 weights found (checked t3_fp32.safetensors and model.safetensors)")
            // Fallback: create model without weights (random init)
            self.t3 = T3Model(config: config)
        }

        // Verify embeddings loaded correctly (for both FP32 and Q4)
        if let t3 = t3 {
            eval(t3.textEmb.weight)
            let min = t3.textEmb.weight.min().item(Float.self)
            let max = t3.textEmb.weight.max().item(Float.self)
            print("‚úÖ textEmb.weight: min=\(min), max=\(max)")

            if min == 0.0 && max == 0.0 {
                print("‚ö†Ô∏è WARNING: Embeddings are zeros - weight loading may have failed!")
            }
        }

        // S3Gen with weight loading
        // Complete FP16 S3Gen weights are in s3gen_fp16.safetensors (preferred)
        // Fallback: Flow encoder weights from model.safetensors + decoder from s3_engine.safetensors
        // Vocoder weights are in vocoder_weights_python.safetensors (extracted from Python with correct shapes)
        let vocoderURL = modelDir.appendingPathComponent("vocoder_weights_python.safetensors")
        let s3genFP16URL = modelDir.appendingPathComponent("s3gen_fp16.safetensors")
        let s3EngineURL = modelDir.appendingPathComponent("s3_engine.safetensors")

        // Try s3gen_fp16.safetensors first (complete FP16 weights), fallback to quantized
        let s3genWeightsURL: URL?
        if FileManager.default.fileExists(atPath: s3genFP16URL.path) {
            print("Found complete FP16 S3Gen weights: s3gen_fp16.safetensors")
            s3genWeightsURL = s3genFP16URL
        } else if FileManager.default.fileExists(atPath: s3EngineURL.path) {
            print("Using s3_engine.safetensors for S3Gen weights (may have quantized components)")
            s3genWeightsURL = s3EngineURL
        } else {
            s3genWeightsURL = nil
        }

        if let s3genURL = s3genWeightsURL {
            print("Loading S3Gen with weights...")

            // Load S3Gen weights (complete FP16 or partial)
            let s3genWeights = try MLX.loadArrays(url: s3genURL)
            print("Loaded \(s3genWeights.count) S3Gen weight arrays")

            // Merge with any additional weights from rawWeights (for quantized encoder etc.)
            // FP16 weights take priority over quantized
            var flowWeights = rawWeights ?? [:]
            for (key, value) in s3genWeights {
                flowWeights[key] = value  // FP16 overwrites quantized
            }
            print("Merged flow weights: \(flowWeights.count) total arrays")

            // Load vocoder weights
            var vocoderWeights: [String: MLXArray]? = nil
            if FileManager.default.fileExists(atPath: vocoderURL.path) {
                vocoderWeights = try MLX.loadArrays(url: vocoderURL)
                print("Loaded \(vocoderWeights?.count ?? 0) vocoder weight arrays")
            }

            // Create S3Gen
            // Set deterministic seed for reproducible bias initialization
            // (nn.Linear initializes bias with random values, not zeros)
            MLXRandom.seed(42)
            self.s3gen = S3Gen(flowWeights: flowWeights, vocoderWeights: vocoderWeights)
            
            // Apply updates
            if let s3 = s3gen {
                let s3Remapped = remapS3Keys(flowWeights)

                // DEBUG: Check encoder keys after remapping
                print("DEBUG: Checking encoder keys in remapped weights:")
                let encoderKeys = s3Remapped.keys.filter { $0.hasPrefix("encoder.") }.sorted()
                print("Found \(encoderKeys.count) encoder keys")
                for key in encoderKeys.prefix(15) {
                    print("  \(key)")
                }

                let s3Params = ModuleParameters.unflattened(s3Remapped)
                s3.update(parameters: s3Params)

                if let vw = vocoderWeights {
                     let vRemapped = remapS3Keys(vw)
                     print("Loaded \(vRemapped.count) remapped vocoder weights")
                     let vParams = ModuleParameters.unflattened(vRemapped)
                     s3.update(parameters: vParams)
                }

                // NOTE: corrected_embed_norm_weights.safetensors was a previous attempt to fix embedNorm
                // but step-by-step verification (TestEncoderTrace) shows the ORIGINAL weights from
                // s3gen_fp16.safetensors produce a PERFECT match with Python. Skipping this "fix".
                // (The issue was elsewhere - key remapping, not weight values)

                // CRITICAL FIX: Load Python's flow decoder weights for perfect fidelity
                // This includes all decoder weights from Python runtime, replacing Swift's weights
                // Also includes 56 attention out_proj.bias weights that were MISSING from Swift entirely
                let pythonFlowURL = modelDir.appendingPathComponent("python_flow_weights.safetensors")
                if FileManager.default.fileExists(atPath: pythonFlowURL.path) {
                    print("Loading Python flow decoder weights for perfect fidelity...")
                    let pythonFlow = try MLX.loadArrays(url: pythonFlowURL)
                    print("  Loaded \(pythonFlow.count) weights from Python")
                    // Keys are already in format: flow.decoder.estimator.down_blocks_0...
                    // Remap to Swift naming: decoder.downBlocks.0...
                    let remappedFlow = remapS3Keys(pythonFlow)
                    print("  Remapped to \(remappedFlow.count) Swift keys")
                    let flowParams = ModuleParameters.unflattened(remappedFlow)
                    s3.update(parameters: flowParams)

                    // Count biases
                    let biasCount = pythonFlow.keys.filter { $0.contains("out_proj.bias") }.count
                    print("‚úÖ Applied Python flow decoder weights (includes \(biasCount) attention biases)")
                } else {
                    print("‚ö†Ô∏è  WARNING: python_flow_weights.safetensors not found!")
                    print("   Decoder will use original weights which differ from Python")
                }

                // NOTE: DO NOT load corrected_embed_norm_weights.safetensors
                // The ORIGINAL weights from s3gen_fp16.safetensors (mean=0.0078) match Python EXACTLY.
                // The "corrected" weights were 22.6x larger and broke Python<->Swift parity.
                // See verify_v2_step6 for verification.
            }
        } else if let flowWeights = rawWeights {
            print("Warning: s3_engine.safetensors not found, S3Gen with encoder weights only")
            let vocoderWeights = FileManager.default.fileExists(atPath: vocoderURL.path)
                ? try MLX.loadArrays(url: vocoderURL) : nil
            // Set deterministic seed for reproducible bias initialization
            MLXRandom.seed(42)
            self.s3gen = S3Gen(flowWeights: flowWeights, vocoderWeights: vocoderWeights)

            if let s3 = s3gen {
                let s3Remapped = remapS3Keys(flowWeights)
                let s3Params = ModuleParameters.unflattened(s3Remapped)
                s3.update(parameters: s3Params)

                if let vw = vocoderWeights {
                     let vRemapped = remapS3Keys(vw)
                     let vParams = ModuleParameters.unflattened(vRemapped)
                     s3.update(parameters: vParams)
                }

                // NOTE: DO NOT load corrected_embed_norm_weights.safetensors
                // The ORIGINAL weights from s3gen_fp16.safetensors (mean=0.0078) match Python EXACTLY.

                // Apply corrected decoder weights
                let correctedDecoderURL = modelDir.appendingPathComponent("corrected_decoder_weights.safetensors")
                if FileManager.default.fileExists(atPath: correctedDecoderURL.path) {
                    print("Loading corrected decoder weights for Python fidelity...")
                    let correctedDecoder = try MLX.loadArrays(url: correctedDecoderURL)
                    let remappedDecoder = remapS3Keys(correctedDecoder)
                    let correctedDecoderParams = ModuleParameters.unflattened(remappedDecoder)
                    s3.update(parameters: correctedDecoderParams)
                    print("‚úÖ Applied corrected decoder weights (56 attention biases)")
                }
            }
        } else {
            print("Error: No weights available for S3Gen")
            fatalError("S3Gen requires flowWeights and vocoderWeights to initialize properly")
        }
        
        s3gen?.train(false)
        print("S3Gen initialized and set to eval mode")

        // Load tokenizer vocab and BPE merges
        let tokenizerURL = modelDir.appendingPathComponent("tokenizer.json")
        if FileManager.default.fileExists(atPath: tokenizerURL.path) {
            print("Loading tokenizer...")
            let (vocabDict, merges) = try loadVocab(from: tokenizerURL)
            self.vocab = vocabDict
            self.bpeMerges = merges
            print("Tokenizer loaded: \(vocab?.count ?? 0) tokens, \(merges.count) BPE merges")
        } else {
            print("Warning: Tokenizer not found")
        }

        isLoaded = true
        print("Models loaded successfully!")
    }

    private func loadWeights(from url: URL) async throws {
        // ... (Legacy method, mostly unused if loadModels does everything, but let's keep it safe)
        print("Loading safetensors from: \(url.lastPathComponent)")
        let rawT3Weights = try MLX.loadArrays(url: url)
        let t3Weights = remapT3Keys(rawT3Weights)
        if let t3 = t3 {
            let t3Params = ModuleParameters.unflattened(t3Weights)
            t3.update(parameters: t3Params)
            t3.train(false)
        }
        
        // Use updated S3Gen logic
        s3gen?.train(false)
    }

    // MARK: - Weight Key Remapping

    private func remapT3Keys(_ weights: [String: MLXArray]) -> [String: MLXArray] {
        var remapped: [String: MLXArray] = [:]
        for (key, value) in weights {
            if let newKey = remapT3Key(key) {
                remapped[newKey] = value
            }
        }
        return remapped
    }

    private func remapT3Key(_ key: String) -> String? {
        var k = key
        if k.hasPrefix("t3.") { k = String(k.dropFirst("t3.".count)) }
        if k.hasPrefix("s3gen.") || k.hasPrefix("ve.") { return nil }

        // Handle FP32 HuggingFace format: tfmr.layers.* ‚Üí layers.*
        if k.hasPrefix("tfmr.layers.") {
            k = String(k.dropFirst("tfmr.".count))
        }
        // Handle Q4 format: tfmr.model.* (but skip embed_tokens)
        else if k.hasPrefix("tfmr.model.") {
            k = String(k.dropFirst("tfmr.model.".count))
            if k.hasPrefix("embed_tokens") { return nil }
        }
        // Handle final norm: tfmr.norm.weight ‚Üí norm.weight
        else if k == "tfmr.norm.weight" {
            k = "norm.weight"
        }
        // Skip other tfmr.* keys
        else if k.hasPrefix("tfmr.") {
            return nil
        }

        if k.hasPrefix("cond_enc.") {
            if k.hasPrefix("cond_enc.spkr_enc.") {
                return k.replacingOccurrences(of: "cond_enc.spkr_enc", with: "speakerProj")
            }
            if k.hasPrefix("cond_enc.perceiver.") {
                // Map perceiver weights: cond_enc.perceiver.* -> perceiver.*
                return k.replacingOccurrences(of: "cond_enc.perceiver", with: "perceiver")
            }
            if k.hasPrefix("cond_enc.emotion_adv_fc.") {
                // Map emotion weights: cond_enc.emotion_adv_fc.* -> emotionAdvFC.*
                return k.replacingOccurrences(of: "cond_enc.emotion_adv_fc", with: "emotionAdvFC")
            }
            return nil
        }

        k = k.replacingOccurrences(of: "self_attn", with: "selfAttn")
        k = k.replacingOccurrences(of: "q_proj", with: "qProj")
        k = k.replacingOccurrences(of: "k_proj", with: "kProj")
        k = k.replacingOccurrences(of: "v_proj", with: "vProj")
        k = k.replacingOccurrences(of: "o_proj", with: "oProj")
        k = k.replacingOccurrences(of: "input_layernorm", with: "inputLayernorm")
        k = k.replacingOccurrences(of: "post_attention_layernorm", with: "postAttentionLayernorm")
        k = k.replacingOccurrences(of: "gate_proj", with: "gateProj")
        k = k.replacingOccurrences(of: "up_proj", with: "upProj")
        k = k.replacingOccurrences(of: "down_proj", with: "downProj")
        k = k.replacingOccurrences(of: "text_emb", with: "textEmb")
        k = k.replacingOccurrences(of: "speech_emb", with: "speechEmb")
        k = k.replacingOccurrences(of: "text_head", with: "textHead")
        k = k.replacingOccurrences(of: "speech_head", with: "speechHead")
        k = k.replacingOccurrences(of: "text_pos_emb.emb", with: "textPosEmb.embedding")
        k = k.replacingOccurrences(of: "speech_pos_emb.emb", with: "speechPosEmb.embedding")

        return k
    }

    private func remapS3Keys(_ weights: [String: MLXArray]) -> [String: MLXArray] {
        var remapped: [String: MLXArray] = [:]
        for (key, value) in weights {
            if let newKey = remapS3Key(key) {
                // Note: Decoder Conv1d weights in s3gen_fp16.safetensors are already in correct MLX format
                remapped[newKey] = value
            }
        }
        return remapped
    }

    /// Remap a single S3Gen weight key (returns nil if key should be skipped)
    private func remapS3Key(_ key: String) -> String? {
        var k = key

        // Map root components from flow.* (handle both with and without s3gen. prefix)
        if k.hasPrefix("s3gen.flow.input_embedding.") {
            return k.replacingOccurrences(of: "s3gen.flow.input_embedding.", with: "inputEmbedding.")
        }
        if k.hasPrefix("flow.input_embedding.") {
            return k.replacingOccurrences(of: "flow.input_embedding.", with: "inputEmbedding.")
        }
        if k.hasPrefix("s3gen.flow.spk_embed_affine_layer.") {
            return k.replacingOccurrences(of: "s3gen.flow.spk_embed_affine_layer.", with: "spkEmbedAffine.")
        }
        if k.hasPrefix("flow.spk_embed_affine_layer.") {
            return k.replacingOccurrences(of: "flow.spk_embed_affine_layer.", with: "spkEmbedAffine.")
        }
        if k.hasPrefix("s3gen.flow.encoder_proj.") {
            return k.replacingOccurrences(of: "s3gen.flow.encoder_proj.", with: "encoderProj.")
        }
        if k.hasPrefix("flow.encoder_proj.") {
            return k.replacingOccurrences(of: "flow.encoder_proj.", with: "encoderProj.")
        }
        
        // Map Encoder (handle both s3gen.flow.encoder. and flow.encoder.)
        // The FP16 file has s3gen.flow.encoder. keys which we want to use
        var isEncoderKey = false
        if k.hasPrefix("s3gen.flow.encoder.") {
            k = k.replacingOccurrences(of: "s3gen.flow.encoder.", with: "encoder.")
            isEncoderKey = true
        } else if k.hasPrefix("flow.encoder.") {
            k = k.replacingOccurrences(of: "flow.encoder.", with: "encoder.")
            isEncoderKey = true
        }

        if isEncoderKey {
            // FlowEncoder uses nested structure matching Python's encoder keys
            // Only minimal remapping needed for naming convention differences

            // Keep embed structure: encoder.embed.linear, encoder.embed.norm, encoder.embed.pos_enc
            // (no flattening needed)

            // Convert snake_case to camelCase for module names
            k = k.replacingOccurrences(of: "pre_lookahead_layer", with: "preLookaheadLayer")
            k = k.replacingOccurrences(of: "up_layer", with: "upLayer")

            // Convert Python's encoders_N to Swift's encoders.N
            for i in 0..<6 { k = k.replacingOccurrences(of: "encoders_\(i).", with: "encoders.\(i).") }
            for i in 0..<4 { k = k.replacingOccurrences(of: "up_encoders.\(i).", with: "upEncoders.\(i).") }

            // Convert after_norm to afterNorm
            k = k.replacingOccurrences(of: "after_norm", with: "afterNorm")
        }

        // Remap mel2wav.* -> vocoder.*
        if k.hasPrefix("mel2wav.") {
            k = k.replacingOccurrences(of: "mel2wav.", with: "vocoder.")
            k = k.replacingOccurrences(of: "conv_pre", with: "convPre")
            k = k.replacingOccurrences(of: "conv_post", with: "convPost")
        }

        // F0 Predictor Mapping - MLX weights use sequential indices 0,1,2,3,4
        // These need vocoder. prefix since they're part of the vocoder (Mel2Wav)
        if k.contains("f0_predictor.") {
             k = k.replacingOccurrences(of: "f0_predictor.condnet.0.", with: "vocoder.f0Predictor.convs.0.")
             k = k.replacingOccurrences(of: "f0_predictor.condnet.1.", with: "vocoder.f0Predictor.convs.1.")
             k = k.replacingOccurrences(of: "f0_predictor.condnet.2.", with: "vocoder.f0Predictor.convs.2.")
             k = k.replacingOccurrences(of: "f0_predictor.condnet.3.", with: "vocoder.f0Predictor.convs.3.")
             k = k.replacingOccurrences(of: "f0_predictor.condnet.4.", with: "vocoder.f0Predictor.convs.4.")
             k = k.replacingOccurrences(of: "f0_predictor.classifier.", with: "vocoder.f0Predictor.classifier.")
             return k
        }

        // Source Module Mapping - needs vocoder. prefix
        if k.contains("m_source.") {
             k = k.replacingOccurrences(of: "m_source.l_linear.", with: "vocoder.mSource.linear.")
             return k
        }

        // Source Downs - needs vocoder. prefix
        if k.contains("source_downs.") {
             k = k.replacingOccurrences(of: "source_downs.", with: "vocoder.sourceDowns.")
             return k
        }

        // Source ResBlocks - needs vocoder. prefix AND activations remapping
        if k.contains("source_resblocks.") {
             k = k.replacingOccurrences(of: "source_resblocks.", with: "vocoder.sourceResBlocks.")
             // Apply activations -> acts remapping
             k = k.replacingOccurrences(of: "activations1", with: "acts1")
             k = k.replacingOccurrences(of: "activations2", with: "acts2")
             return k
        }

        // Handle direct vocoder weights (no mel2wav. prefix) from vocoder_weights_python.safetensors
        if k.hasPrefix("conv_pre") || k.hasPrefix("conv_post") || k.hasPrefix("resblocks") || k.hasPrefix("ups") {
            // Add vocoder. prefix and convert to camelCase
            k = "vocoder." + k
            k = k.replacingOccurrences(of: "conv_pre", with: "convPre")
            k = k.replacingOccurrences(of: "conv_post", with: "convPost")
            // Remap activations -> acts
            k = k.replacingOccurrences(of: "activations1", with: "acts1")
            k = k.replacingOccurrences(of: "activations2", with: "acts2")
        }

        // Transform flow.decoder.estimator.* -> decoder.* (handle both with and without s3gen. prefix)
        if k.hasPrefix("s3gen.flow.decoder.estimator.") {
             k = k.replacingOccurrences(of: "s3gen.flow.decoder.estimator.", with: "decoder.")
        } else if k.hasPrefix("flow.decoder.estimator.") {
             k = k.replacingOccurrences(of: "flow.decoder.estimator.", with: "decoder.")
        }
        
        if k.contains("rand_noise") { return nil }

        // Block names
        k = k.replacingOccurrences(of: "down_blocks_", with: "downBlocks.")
        k = k.replacingOccurrences(of: "mid_blocks_", with: "midBlocks.")
        k = k.replacingOccurrences(of: "up_blocks_", with: "upBlocks.")

        // ResNet components
        // CausalBlock1D uses .conv.conv
        // Python keys: .block1.conv.conv.weight
        // Swift keys: .block1.conv.conv.weight
        
        k = k.replacingOccurrences(of: "mlp_linear", with: "mlpLinear")
        k = k.replacingOccurrences(of: "res_conv", with: "resConv")

        // Transform transformer components
        k = k.replacingOccurrences(of: ".transformer_", with: ".transformers.")
        // Python uses .attn. but Swift uses .attention.
        k = k.replacingOccurrences(of: ".attn.", with: ".attention.")
        k = k.replacingOccurrences(of: "query_proj", with: "queryProj")
        k = k.replacingOccurrences(of: "key_proj", with: "keyProj")
        k = k.replacingOccurrences(of: "value_proj", with: "valueProj")
        k = k.replacingOccurrences(of: "out_proj", with: "outProj")
        
        // Map Conformer Attention Names (linear_*) to Standard Names
        k = k.replacingOccurrences(of: "linear_q", with: "queryProj")
        k = k.replacingOccurrences(of: "linear_k", with: "keyProj")
        k = k.replacingOccurrences(of: "linear_v", with: "valueProj")
        k = k.replacingOccurrences(of: "linear_out", with: "outProj")

        if k.contains(".norm3.") {
            k = k.replacingOccurrences(of: ".norm3.", with: ".norm2.")
        }
        k = k.replacingOccurrences(of: "ff.net.0.", with: "ff.layers.0.")
        k = k.replacingOccurrences(of: "ff.net.2.", with: "ff.layers.1.")
        
        k = k.replacingOccurrences(of: "time_mlp", with: "timeMLP")
        k = k.replacingOccurrences(of: "timeMLP.0.", with: "timeMLP.linear1.")
        k = k.replacingOccurrences(of: "timeMLP.2.", with: "timeMLP.linear2.")
        // Python uses linear_1/linear_2, Swift uses linear1/linear2
        k = k.replacingOccurrences(of: ".linear_1.", with: ".linear1.")
        k = k.replacingOccurrences(of: ".linear_2.", with: ".linear2.")
        
        k = k.replacingOccurrences(of: "downsample", with: "downLayer")
        k = k.replacingOccurrences(of: "upsample", with: "upLayer")
        k = k.replacingOccurrences(of: "final_block", with: "finalBlock")
        k = k.replacingOccurrences(of: "final_proj", with: "finalProj")
        
        k = k.replacingOccurrences(of: "act_post", with: "actPost")
        
        return k
    }

    // MARK: - Voice Loading (Dual Soul Injection)

    public func loadVoice(_ name: String, from bundle: Bundle = .main, voicesURL: URL? = nil) throws {
        print("Loading voice: \(name)")

        let voiceDir: URL
        if let url = voicesURL {
             voiceDir = url.appendingPathComponent(name)
        } else if let url = bundle.url(forResource: "voices", withExtension: nil)?.appendingPathComponent(name) {
             voiceDir = url
        } else {
             throw ChatterboxError.voiceNotFound("voices/\(name) directory not found in bundle")
        }
        
        if !FileManager.default.fileExists(atPath: voiceDir.path) {
             throw ChatterboxError.voiceNotFound("Voice directory not found at: \(voiceDir.path)")
        }

        // Load T3 speaker embedding from prebaked voice
        let t3SoulURL = voiceDir.appendingPathComponent("soul_t3_256.npy")
        var t3SoulLoaded = try MLXArray.load(npy: t3SoulURL)
        // Ensure batch dimension: [256] -> [1, 256]
        if t3SoulLoaded.ndim == 1 {
            t3SoulLoaded = t3SoulLoaded.expandedDimensions(axis: 0)
        }
        self.t3Soul = t3SoulLoaded
        print("T3 Soul (speaker embedding) loaded: shape \(t3Soul!.shape)")

        let s3SoulURL = voiceDir.appendingPathComponent("soul_s3_192.npy")
        self.s3Soul = try MLXArray.load(npy: s3SoulURL)
        print("S3 Soul loaded: shape \(s3Soul!.shape)")

        let condTokensURL = voiceDir.appendingPathComponent("t3_cond_tokens.npy")
        self.t3CondTokens = try MLXArray.load(npy: condTokensURL)
        print("T3 cond tokens loaded: shape \(t3CondTokens!.shape)")

        let promptTokenURL = voiceDir.appendingPathComponent("prompt_token.npy")
        self.promptToken = try MLXArray.load(npy: promptTokenURL)

        let promptFeatURL = voiceDir.appendingPathComponent("prompt_feat.npy")
        self.promptFeat = try MLXArray.load(npy: promptFeatURL)

        isVoiceLoaded = true
        print("Dual Souls injected for: \(name)")
    }

    // MARK: - Speech Generation

    public func speak(_ text: String, temperature: Float = 0.3) async throws {
        guard isLoaded else { throw ChatterboxError.modelNotLoaded }
        guard isVoiceLoaded else { throw ChatterboxError.voiceNotLoaded }
        guard let t3 = t3, let s3gen = s3gen, let t3Soul = t3Soul, let s3Soul = s3Soul,
              let t3CondTokens = t3CondTokens, let promptToken = promptToken, let promptFeat = promptFeat else {
            throw ChatterboxError.modelNotLoaded
        }

        print("Generating speech for: \"\(text)\"")

        let tokens = tokenize(text)
        let textTokens = MLXArray(tokens.map { Int32($0) }).expandedDimensions(axis: 0)

        print("Text tokens: \(tokens.count)")
        print("Starting T3 generation...")
        let startTime = CFAbsoluteTimeGetCurrent()

        var currentCondTokens = t3CondTokens
        if !lastSpeechTokens.isEmpty {
            let suffix = lastSpeechTokens.suffix(150)
            currentCondTokens = MLXArray(suffix.map { Int32($0) }).expandedDimensions(axis: 0)
            print("Using token chaining prompt (\(suffix.count) tokens)")
        }

        let speechTokens = t3.generate(
            textTokens: textTokens,
            speakerEmb: t3Soul,
            condTokens: currentCondTokens,
            maxTokens: 150,
            temperature: temperature
        )

        let elapsed = CFAbsoluteTimeGetCurrent() - startTime
        print("Generated \(speechTokens.count) speech tokens in \(String(format: "%.2f", elapsed))s")

        // Filter out invalid tokens (>= 6561) - same as Python's drop_invalid_tokens
        let validTokens = speechTokens.filter { $0 < 6561 }
        print("Filtered to \(validTokens.count) valid tokens")

        print("Clearing GPU memory before S3Gen...")
        GPU.clearCache()

        print("Starting S3Gen synthesis...")
        let speechTokenArray = MLXArray(validTokens.map { Int32($0) }).expandedDimensions(axis: 0)
        let audio = s3gen.generate(
            tokens: speechTokenArray,
            speakerEmb: s3Soul,
            speechEmbMatrix: t3.speechEmb.weight,
            promptToken: promptToken,
            promptFeat: promptFeat
        )

        print("Playing audio: \(audio.shape) samples")
        eval(audio)
        playAudio(audio)

        lastSpeechTokens.append(contentsOf: validTokens)
        if lastSpeechTokens.count > 500 {
            lastSpeechTokens = Array(lastSpeechTokens.suffix(500))
        }
    }

    public func speakStreaming(_ text: String, chunkSize: Int = 50, temperature: Float = 0.3) async throws {
        // Implementation similar to speak but chunked. 
        // For brevity in this fix, reusing standard logic pattern.
        // Assuming user will use 'speak' for testing in main.swift
        try await speak(text, temperature: temperature)
    }

    // MARK: - Tokenization

    private func loadVocab(from url: URL) throws -> ([String: Int], [(String, String)]) {
        let data = try Data(contentsOf: url)
        let json = try JSONSerialization.jsonObject(with: data) as? [String: Any]
        guard let model = json?["model"] as? [String: Any],
              let vocabDict = model["vocab"] as? [String: Int] else {
            throw ChatterboxError.generationFailed("Invalid tokenizer.json format")
        }

        // Load BPE merges
        var merges: [(String, String)] = []
        if let mergeStrings = model["merges"] as? [String] {
            for mergeStr in mergeStrings {
                let parts = mergeStr.split(separator: " ", maxSplits: 1)
                if parts.count == 2 {
                    merges.append((String(parts[0]), String(parts[1])))
                }
            }
        }
        print("Loaded BPE vocab with \(vocabDict.count) tokens and \(merges.count) merge rules")
        return (vocabDict, merges)
    }

    public func tokenize(_ text: String) -> [Int] {
        guard let vocab = vocab, let merges = bpeMerges else {
            return text.unicodeScalars.map { Int($0.value) % 704 }
        }

        var tokens: [Int] = []

        // NOTE: DO NOT add BOS/EOS tokens - Python tokenizer doesn't add them
        // The T3 model adds start_speech_token (6561) internally during generation

        // Pre-tokenize: split on whitespace (as per tokenizer.json pre_tokenizer)
        let words = text.components(separatedBy: .whitespaces).filter { !$0.isEmpty }

        for word in words {
            // BPE encode this word
            let wordTokens = bpeEncode(word: word, vocab: vocab, merges: merges)
            tokens.append(contentsOf: wordTokens)

            // DO NOT add space tokens - Python tokenizer doesn't use them
            // Spaces are implicit in BPE and handled during decoding
        }

        // NOTE: DO NOT add stop_text_token - Python doesn't add it

        return tokens
    }

    /// BPE encode a single word (no spaces)
    private func bpeEncode(word: String, vocab: [String: Int], merges: [(String, String)]) -> [Int] {
        // Start with individual characters
        var symbols = word.map { String($0) }

        // Create a set of merge rules for fast lookup, preserving order via index
        var mergeRanks: [String: Int] = [:]
        for (index, merge) in merges.enumerated() {
            let key = "\(merge.0) \(merge.1)"
            mergeRanks[key] = index
        }

        // Apply merges iteratively
        while symbols.count > 1 {
            // Find the pair with the lowest merge rank
            var bestPair: (Int, String, String)? = nil  // (index, left, right)
            var bestRank = Int.max

            for i in 0..<(symbols.count - 1) {
                let pair = "\(symbols[i]) \(symbols[i + 1])"
                if let rank = mergeRanks[pair], rank < bestRank {
                    bestRank = rank
                    bestPair = (i, symbols[i], symbols[i + 1])
                }
            }

            // If no merge found, we're done
            guard let (idx, left, right) = bestPair else { break }

            // Apply the merge
            symbols[idx] = left + right
            symbols.remove(at: idx + 1)
        }

        // Convert symbols to token IDs
        var tokenIds: [Int] = []
        for symbol in symbols {
            if let tokenId = vocab[symbol] {
                tokenIds.append(tokenId)
            } else {
                // Unknown token - use [UNK] = 1
                tokenIds.append(1)
            }
        }

        return tokenIds
    }

    // MARK: - Audio Playback

    private func playAudio(_ audio: MLXArray) {
        let samples = audio.asArray(Float.self)
        guard !samples.isEmpty else { return }
        guard let buffer = AVAudioPCMBuffer(pcmFormat: audioFormat, frameCapacity: AVAudioFrameCount(samples.count)) else { return }
        buffer.frameLength = AVAudioFrameCount(samples.count)
        if let channelData = buffer.floatChannelData {
            for i in 0..<samples.count { channelData[0][i] = samples[i] }
        }
        audioPlayer.scheduleBuffer(buffer) { print("Audio chunk finished playing") }
    }

    public func stop() {
        audioPlayer.stop()
        audioPlayer.play()
    }

    public func resetState() {
        lastSpeechTokens.removeAll()
        print("Voice state reset")
    }

    // MARK: - Audio Generation (returns data instead of playing)

    public func generateAudio(_ text: String, temperature: Float = 0.4) async throws -> [Float] {
        print("DEBUG: generateAudio() called with text: \"\(text)\""); fflush(stdout)
        guard isLoaded else { throw ChatterboxError.modelNotLoaded }
        guard isVoiceLoaded else { throw ChatterboxError.voiceNotLoaded }
        guard let t3 = t3, let s3gen = s3gen, let t3Soul = t3Soul, let s3Soul = s3Soul,
              let t3CondTokens = t3CondTokens, let promptToken = promptToken, let promptFeat = promptFeat else {
            throw ChatterboxError.modelNotLoaded
        }
        print("DEBUG: Guards passed"); fflush(stdout)

        print("DEBUG: Tokenizing text..."); fflush(stdout)
        let tokens = tokenize(text)
        print("DEBUG: Got \(tokens.count) tokens"); fflush(stdout)
        print("DEBUG: Token values: \(tokens.prefix(20))... (showing first 20)"); fflush(stdout)
        print("DEBUG: Python would produce 42 tokens: [255, 284, 18, 84, ...]"); fflush(stdout)
        let textTokens = MLXArray(tokens.map { Int32($0) }).expandedDimensions(axis: 0)
        print("DEBUG: Created textTokens MLXArray: \(textTokens.shape)"); fflush(stdout)

        var currentCondTokens = t3CondTokens
        if !lastSpeechTokens.isEmpty {
            let suffix = lastSpeechTokens.suffix(150)
            currentCondTokens = MLXArray(suffix.map { Int32($0) }).expandedDimensions(axis: 0)
        }
        print("DEBUG: currentCondTokens: \(currentCondTokens.shape)"); fflush(stdout)

        // üî¨ CONDITIONING TOKENS DIAGNOSTIC
        eval(currentCondTokens)
        let condFlat = currentCondTokens.reshaped([-1])
        let condFirst20 = condFlat[0..<min(20, condFlat.shape[0])]
        eval(condFirst20)
        print("üî¨ Conditioning tokens [:20]: \(condFirst20.asArray(Int32.self))")
        print("   Expected: [3782, 6486, 6405, 4218, 2031, 2922, 2203, 4814, 4813, 4850, 395, 395, 395, 638, 638, 638, 2582, 2582, 1520, 2031]")

        print("DEBUG: Calling T3 generate..."); fflush(stdout)
        // Match Python FP32 default (1.2) since we're using FP32 T3 weights
        // Note: Q4 quantized models may need 1.8 to avoid loops, but FP32 works best at 1.2
        let speechTokens = t3.generate(
            textTokens: textTokens,
            speakerEmb: t3Soul,
            condTokens: currentCondTokens,
            maxTokens: 150,
            temperature: temperature,
            repetitionPenalty: 1.2  // Match Python FP32 (was 1.8 for Q4)
        )
        print("DEBUG: T3 generate returned \(speechTokens.count) speech tokens"); fflush(stdout)

        // üî¨ TOKEN DIAGNOSTIC: Save tokens to file for comparison with Python
        let tokensString = speechTokens.map { String($0) }.joined(separator: ", ")
        let tokensURL = URL(fileURLWithPath: "/Users/a10n/Projects/chatterbox claude/swift_generated_tokens.txt")
        try? tokensString.write(to: tokensURL, atomically: true, encoding: .utf8)
        print("üíæ Saved tokens to: swift_generated_tokens.txt"); fflush(stdout)

        // DIAGNOSTIC: Print first 20 tokens to check range
        let first20 = Array(speechTokens.prefix(20))
        print("üîç First 20 speech tokens: \(first20)"); fflush(stdout)
        if let minToken = speechTokens.min(), let maxToken = speechTokens.max() {
            print("üîç Token range: min=\(minToken), max=\(maxToken)"); fflush(stdout)
        }

        // Filter out invalid tokens (>= 6561) - same as Python's drop_invalid_tokens
        // S3Gen embedding vocab is 6561, tokens >= 6561 are special tokens
        let validTokens = speechTokens.filter { $0 < 6561 }
        print("DEBUG: Filtered to \(validTokens.count) valid tokens (removed \(speechTokens.count - validTokens.count) invalid)"); fflush(stdout)

        GPU.clearCache()
        print("DEBUG: GPU cache cleared"); fflush(stdout)

        print("DEBUG: Converting speech tokens to MLXArray..."); fflush(stdout)
        let speechTokenArray = MLXArray(validTokens.map { Int32($0) }).expandedDimensions(axis: 0)
        print("DEBUG: speechTokenArray: \(speechTokenArray.shape)"); fflush(stdout)

        print("DEBUG: Calling S3Gen generate..."); fflush(stdout)

        // üî¨ S3GEN INPUT DIAGNOSTICS
        eval(s3Soul, promptToken, promptFeat)
        print("üî¨ S3GEN INPUT VERIFICATION:")
        print("   S3 Soul shape: \(s3Soul.shape) ‚úÖ")
        print("   Prompt Token shape: \(promptToken.shape)")
        print("   Prompt Feat shape: \(promptFeat.shape)")
        print("   Speech tokens count: \(validTokens.count)")

        // Check for any nil or wrong shapes
        if promptToken.shape[0] == 0 || promptFeat.shape[0] == 0 {
            print("‚ùå WARNING: Prompt token or feat is empty!")
        }

        let audio = s3gen.generate(
            tokens: speechTokenArray,
            speakerEmb: s3Soul,
            speechEmbMatrix: t3.speechEmb.weight,
            promptToken: promptToken,
            promptFeat: promptFeat
        )
        print("DEBUG: S3Gen generate returned, audio shape: \(audio.shape)"); fflush(stdout)

        print("DEBUG: Evaluating audio..."); fflush(stdout)
        eval(audio)
        print("DEBUG: Audio evaluated"); fflush(stdout)

        lastSpeechTokens.append(contentsOf: validTokens)
        if lastSpeechTokens.count > 500 {
            lastSpeechTokens = Array(lastSpeechTokens.suffix(500))
        }

        print("DEBUG: Converting to Float array..."); fflush(stdout)
        let result = audio.asArray(Float.self)
        print("DEBUG: Conversion complete, returning \(result.count) samples"); fflush(stdout)
        return result
    }

    // MARK: - S3Gen Only (for testing with pre-generated tokens)

    /// Run S3Gen with pre-generated speech tokens (skipping T3 entirely)
    /// This is used for cross-testing between Python and Swift implementations
    public func runS3GenOnly(
        speechTokens: MLXArray,
        promptTokens: MLXArray,
        promptFeat: MLXArray,
        s3Soul: MLXArray
    ) async throws -> [Float] {
        guard isLoaded else { throw ChatterboxError.modelNotLoaded }
        guard let s3gen = s3gen, let t3 = t3 else {
            throw ChatterboxError.modelNotLoaded
        }

        print("Running S3Gen with pre-generated tokens...")
        print("  Speech tokens: \(speechTokens.shape)")
        print("  Prompt tokens: \(promptTokens.shape)")
        print("  Prompt feat: \(promptFeat.shape)")
        print("  S3 Soul: \(s3Soul.shape)\n")

        // Extract tokens to check validity
        eval(speechTokens)
        let tokensFlat = speechTokens.reshaped([-1]).asArray(Int32.self)
        let validTokens = tokensFlat.filter { $0 < 6561 }

        print("Token validation:")
        print("  Total tokens: \(tokensFlat.count)")
        print("  Valid tokens (<6561): \(validTokens.count)")
        print("  Invalid tokens: \(tokensFlat.count - validTokens.count)")
        print("  First 10: \(validTokens.prefix(10))")
        print("  Last 10: \(validTokens.suffix(10))\n")

        // Use valid tokens
        let validTokenArray = MLXArray(validTokens).expandedDimensions(axis: 0)

        GPU.clearCache()

        // Run S3Gen
        let audio = s3gen.generate(
            tokens: validTokenArray,
            speakerEmb: s3Soul,
            speechEmbMatrix: t3.speechEmb.weight,
            promptToken: promptTokens,
            promptFeat: promptFeat
        )

        eval(audio)

        let result = audio.asArray(Float.self)
        print("Generated \(result.count) audio samples (\(String(format: "%.2f", Float(result.count) / 24000.0))s)\n")

        return result
    }

    // MARK: - WAV File Writing

    public static func saveWav(_ samples: [Float], to url: URL, sampleRate: Int = 24000) throws {
        let format = AVAudioFormat(standardFormatWithSampleRate: Double(sampleRate), channels: 1)!
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(samples.count)) else {
            throw ChatterboxError.generationFailed("Failed to create audio buffer")
        }
        buffer.frameLength = AVAudioFrameCount(samples.count)
        if let channelData = buffer.floatChannelData {
            for i in 0..<samples.count {
                channelData[0][i] = samples[i]
            }
        }

        let file = try AVAudioFile(forWriting: url, settings: format.settings)
        try file.write(from: buffer)
        print("Saved WAV to: \(url.path)")
    }
}

public enum ChatterboxError: Error, LocalizedError {
    case modelNotFound(String)
    case voiceNotFound(String)
    case modelNotLoaded
    case voiceNotLoaded
    case generationFailed(String)

    public var errorDescription: String? {
        switch self {
        case .modelNotFound(let path): return "Model not found: \(path)"
        case .voiceNotFound(let path): return "Voice not found: \(path)"
        case .modelNotLoaded: return "Model not loaded. Call loadModels() first."
        case .voiceNotLoaded: return "Voice not loaded. Call loadVoice() first."
        case .generationFailed(let reason): return "Generation failed: \(reason)"
        }
    }
}
